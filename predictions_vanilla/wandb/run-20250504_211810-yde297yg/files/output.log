[34m[1mwandb[0m: [33mWARNING[0m Config item 'emb_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'layer_type' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'hidden_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'enc_layers' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'dec_layers' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'dropout' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'teacher_force_ratio' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'epochs' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'bidirectional' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'beam_width' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'val_beam_search' was locked by 'sweep' (ignored update).
The model has 1,370,688 trainable parameters

Epoch 1/5                                        Teacher Forcing Ratio: 0.5000
--------------------------------------------------------------------------------
Training Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2955/2955 [01:33<00:00, 31.57it/s, loss=3.07]
Train Loss: 3.0656 | Train Char Acc: 0.2074 | Train Seq Acc: 0.0000
Evaluation Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 290/290 [00:11<00:00, 25.23it/s, loss=3.23]
Val   Loss: 3.2195 | Val Char Acc: 0.0737 | Val Seq Acc: 0.0000
Validation improved, but waiting to confirm best over next 3 epochs...

Epoch Time: 1.0m 45.10804462432861s

Epoch 2/5                                        Teacher Forcing Ratio: 0.4756
--------------------------------------------------------------------------------
Training Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2955/2955 [01:33<00:00, 31.68it/s, loss=2.9] 
Train Loss: 2.9327 | Train Char Acc: 0.2412 | Train Seq Acc: 0.0000
Evaluation Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 290/290 [00:19<00:00, 14.60it/s, loss=3.35]
Val   Loss: 3.3276 | Val Char Acc: 0.1249 | Val Seq Acc: 0.0000
 No improvement. Patience: 1/3

Epoch Time: 1.0m 53.13191294670105s

Epoch 3/5                                        Teacher Forcing Ratio: 0.4524
--------------------------------------------------------------------------------
Training Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2955/2955 [01:31<00:00, 32.15it/s, loss=2.63]
Train Loss: 2.8401 | Train Char Acc: 0.2683 | Train Seq Acc: 0.0000
Evaluation Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 290/290 [00:22<00:00, 12.77it/s, loss=3.55]
Val   Loss: 3.3979 | Val Char Acc: 0.1174 | Val Seq Acc: 0.0000
 No improvement. Patience: 2/3

Epoch Time: 1.0m 54.621126890182495s

Epoch 4/5                                        Teacher Forcing Ratio: 0.4304
--------------------------------------------------------------------------------
Training Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2955/2955 [01:31<00:00, 32.38it/s, loss=2.88]
Train Loss: 2.8194 | Train Char Acc: 0.2721 | Train Seq Acc: 0.0000
Evaluation Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 290/290 [00:21<00:00, 13.51it/s, loss=3.3] 
Val   Loss: 3.3582 | Val Char Acc: 0.1118 | Val Seq Acc: 0.0000
 No improvement. Patience: 3/3

 Saving best model from 1 epoch(s) ago with val loss: 3.2195
 Best model saved to: best_model.pt

Training ended before confirming best model due to patience.

++++++++++++++++++++++++<Training Ended after 5 Epochs>++++++++++++++++++++++++



++++++++++++++++++++++++++++<Testing Phase Started>++++++++++++++++++++++++++++
Preparing test dataset...

Loading best model for test evaluation...
Evaluation Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 289/289 [00:12<00:00, 23.41it/s, loss=2.68]

 Test Loss: 3.2354 | Test Char Acc: 0.0759 | Test Seq Acc: 0.0000
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
